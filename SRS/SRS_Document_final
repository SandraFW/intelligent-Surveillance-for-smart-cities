\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{makecell}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage[normalem]{ulem}
\usepackage{placeins}
\renewcommand\theadalign{bc}
\renewcommand\theadfont{\bfseries}
\renewcommand\theadgape{\Gape[4pt]}
\renewcommand\cellgape{\Gape[4pt]}

\usepackage[
backend=biber,
style=numeric,
sorting=none,
citestyle=ieee
]{biblatex}

\addbibresource{Ref.bib}

%opening
\title{Software Requirement Specification Document 
\newline For Intelligent Surveillance system for smart cities}

\author{
Nour Ahmed, Nour ElHoda Hisham, Mariam Hesham, Samiha Hesham, Sandra Fares\\
Supervised by:
Dr. Islam Tharwat, Eng. Lobna Mostafa
}

\begin{document}
\maketitle

\begin{table}[htp]
\caption{Document version history}
\begin{center}
\begin{tabular}{|c|c|l|}
\hline
\thead{Version}    & \thead{Date} & \thead{Reason for Change}  \\ \hline
1.0 & 12-Dec-2020   & \makecell[l]{SRS First version’s specifications are defined.}   \\ \hline
1.1 & 20-Dec-2020   & \makecell[l]{Added Non-Functional Requirements\\Identified remaining functional requirements.\\Identified hardware constraints\\Added end user Interface} \\ \hline
1.3 & 28-Dec-2020   & \makecell[l]{Non-Functional Requirements are updated.\\ Added class diagram and data base schema\\Added use case for actors in the system and operational scenarios} \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[htp]
\begin{tabular}{cc}
\thead{GitHub:}    & {https://github.com/SandraFW/intelligent-Surveillance-for-smart-cities}   
\end{tabular}
\end{table}

\pagebreak
\begin{abstract}
Surveillance systems are of vital importance for the development of smart cities \cite{7823349}. These systems can be considered vision organs of such cities. It is expected that a huge amount of data (Big Data) will be generated in smart cities. Therefore, to ensure the safety of its citizens, it is important to provide an efficient and real-time analysis of these data to get real-time responses, when catastrophic events occur. Accordingly, transmitting this massive data to the cloud, to be processed, is relatively slow as proved in \cite{10.1007/978-3-030-44372-6_5}. Therefore, the purpose of this project is to implement an edge computing- based surveillance system to offer real-time data processing. When surveillance videos capture an incident, the data get transferred to the edge for processing. Moreover, a rapid response is then provided to properly handle the occasion. Furthermore, despite tackling scalability obstacles, the system should handle privacy-sensitive data to overcome the privacy challenges in smart cities.
\end{abstract}

\section{Introduction}

\subsection{Purpose of this document}
The purpose of this document is to present a detailed description of how to use edge-fog model to handle kidnapping cases and reduce kidnapping.
It will figure both functional and non-functional requirements of the system in addition to the interfaces, GUI and constraints that will 
cover the system. Moreover, this document will define both stakeholders and developers of the system.

\subsection{Scope of this document}
The scope of this document is to show the basic outlines of our system requirements in order to understand our system for any further updates later on and the issues we may face.Further more,the objectives that we will reach in our system.Requirements outlined in this document are subject to be changed. 
\subsection{System Overview}

\begin{figure}[htp]
\centering
\includegraphics[width=15cm,height=10cm,keepaspectratio]{./D2.jpeg}
\caption{Illustration of high-level view of the system.}
\label{3layers}
\end{figure}
The system aims to prevent kidnapping acts in smart cities by fast prediction and detection of those incidents, using a framework composed of three computing layers as shown in Figure \ref{3layers}, as some authors proposed in their papers \cite{8633626}, \cite{10.1145/3132479.3132490}, \cite{9126126} and \cite{sultana2019iot}. First, the cameras located at the potential crime scenes act as the edge nodes; Light-weighted algorithms are deployed on them for any possible failure in the device and human motion detection. Once it detects abnormal motion, the data moves to the second layer, which is the fog nodes layer, where the processing is completed and alerts are generated to the authorities, with possibilities to track and detect the kidnapper’s face too. Then transmits the data to the third layer, the cloud layer where data backup and system updates are done. The system must ensure safety and privacy measures for the citizens while using and transferring the captured data throughout the day.\newpage
\subsection{System Scope}
\begin{itemize}
\item Fog/Edge computing-based surveillance system to monitoring the whole city 24/7.
\item Efficiently detect any abnormal actions caused by human behavior and response immediately.
\item Privacy assurance by blur people’s faces to secure their exposed identity in the video.
\item Scalability system to handle such massive data generated from surveillance cameras and sensors.
\item Efficiently detection for any failure that impacts the usefulness of the video streams.
\item Dispatch crime details (i.e., video and location of the event, criminal's face) and giving alert to the nearest competent authority.
\item Applying a prediction function to predict possible abnormal events.
\item Providing efficient real-time tracking for the criminal in case of detecting a massive crime.
\item Face recognition for a criminal when an event occurs in the far distance through high-resolution video.
\end{itemize} 

\subsection{Business Context}
The proposed system is implemented to reduce kidnapping rates. By using fog-edge computing in camera sensors, it will be easy to detect kidnapping or predict it before happening, also it would recognize the criminal by face recognition. Moreover, it will alert the police to track him. The most important thing that fog computing has an important role in storing and processing essential surveillance data to give real time response.
\section{Similar Systems}
\subsection{Academic}
\begin{itemize}
\item In the hopes of decreasing and preventing crimes in a smart home environment (SHE), Tanin Sultana and Khan A. Wahid \cite{sultana2019iot} proposed a framework called IoT guard. The authors designed an edge-fog architecture to assist in detecting crimes, predicting them, and sending alerts to police units to take immediate actions and prevent any catastrophic event from occurring. As shown in Figure \ref{security}, Initially, the edge nodes, or the cameras, detect if an event took place. Whenever an action is detected, the edge nodes will forward the surveillance data to the fog nodes to get processed. The fog nodes will then apply object detection algorithms, predict possible events, send alerts to the police unit, and finally send data to the cloud server for system updates or any further analysis. Results show the system’s performance is better than transitional IoT surveillance systems. It is efficient and scalable. Other systems that target the safety of the citizens include \cite{neto2018fog}, which ensures the public’s safety using an application for Smart Transportation Safety (STS), and \cite{pujol2019soft} which detects any violent act that occurs on social media platforms. 

\begin{figure}[htp]
    \centering
    \includegraphics[width=12cm]{Screenshot (299).png}
    \caption{IoT-guard security management system}
    \label{security}
\end{figure}
\newpage
\item Hui Sun et al. \cite{sun2019vu} presented an edge computing-enabled video usefulness model (VU) in order to handle failures that might occur in surveillance videos, using failure detection approaches, as it usually takes a great amount of time for maintenance teams to determine what causes the failure. Moreover, the system provides bandwidth improvement, as useless video surveillance data might consume bandwidth that is needed by useful and informative videos. Experimental results show that the system detects failures efficiently. Various systems' target, like this one, is to make use of useful information. In \cite{hussain2020multi} a multi-view video summarization is presented to extract convenient data. Moreover, a survey paper \cite{hussain2020comprehensive} is published to discuss this system's objectives, advantages, and drawbacks.
\item Due to the large number of data collected by surveillance cameras, many challenges appeared in analyzing, storing, and retrieving data. Santamaria et al. \cite{santamaria2019cooperative} introduced the basics needed to build a framework for people’s abnormal behaviors, after investigating the current techniques and technologies. The authors proposed a distributed architecture as shown in Figure \ref{Santamaria}. Distributed architectures assist in reducing the computation of the end devices, which help in improving the performance and avoiding waste of bandwidth and memory.  In addition, they mentioned the responsibility of each layer in the system, the possible computer vision techniques that can be used with their pros and cons as Neural networks, and the KNN model for object detection and tracking. Results show that an alarm is triggered when detecting an anomaly in  order to track it. Other systems that aimed to improve the performance include \cite{baldoni2017dynamic}
\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=10.0cm, height=10.0cm]{./4.png}
  \caption{the distributed ecosystem in cloud domain}
  \label{Santamaria}
 \end{minipage}
\end{figure}

\newpage
\item Jianyu Wang et al. \cite{wang2017elastic} designed fog computing architecture for urban surveillance systems to provide low latency and decrease the workload of cloud centers. The authors implemented Network Functions Virtualization and Software-Defined Networking on the cloud computing platform OpenStack, resulting in a real-time video processing system. Experimental results are promising. They show that the system can be developed on a larger scale and that fog computing can be potentially used for smart urban surveillance systems. Likewise, Yutong Liu et al. \cite{liu2019litedge} also proposed a system that improves the latency, as well as the accuracy.
\item In the hopes of exploiting fog computing and tackling the cost challenges faced when building surveillance systems, Mansoor Nasir et al \cite{nasir2019fog} presented a cost-effective fog computing based surveillance system. The system does not only reduce the energy consumed and the bandwidth, but also reduces the cost. The authors proposed a video summarization technique to reach their goal. By using Raspberry Pi devices as the system’s fog nodes, and by distributing data onto these nodes to provide a summary, the system is scalable and delivers satisfactory outcomes. Other systems that provide cost-effective surveillance solutions using fog computing include \cite{mohamed2017uavfog} and \cite{ding2018cost}
 
\end{itemize}


\subsection{Business Applications}
\begin{itemize}
\item For helping smart cities to achieve a safe and secure environment, Logipix \cite{logipix} Technical Development Ltd is a privately held organization founded in 1996 in Hungary that provides intelligent video monitoring solutions for wide public areas in the cities. They highlighted their solutions as a scalable city-wide system that is designed and developed to achieve a video surveillance system and traffic violation management tasks at the same time. The main goal of Logipix solutions is to provide a real-time system that is able to surveil the whole city 24/7 efficiently, the system also can respond immediately and take proper action in case of detecting any abnormal event. Moreover, the system captures all the events with high resolution even at miles away, face recognition is still possible. For helping the competent authorities, these recordings can be used as unappealable evidence on demand.

\item BT Business \cite{BT} is a retail division of the United Kingdom telecommunications company that provides many solutions that build smart cities. For securing smart cities and in order to help the administrators make swift decisions and help them to fast respond to what’s going on and to prevent suspicious events before they happen, BT provides surveillance solutions for local councils, streets, public transport , police stations and more. Moreover, they helped many United Kingdom cities to turn to smart cities by the installation of public WiFi and cameras to help monitor traffics, give real-time alerts for trams, buses and more. For cost-effective and best-of-breed surveillance solutions, BT company partners with industry-leading suppliers as CISCO and BOSCH and many other huge suppliers.
\end{itemize} 
\newpage
\section{System Description}

\subsection{User Problem Statement}
One of the problems that face inhabitants in smart cities is kidnapping. Nowadays, the rate of kidnapping is rapidly increasing as shown in \cite{knoema}, which threatens national security. Moreover, real-time response is needed to prevent or avoid any catastrophic event from occurring.
\subsection{ User Objectives}
Our system is crucial, as its fundamental goal is to ensure the citizens’ safety. For our users, the system should provide a rapid response to take appropriate action in time. When an anomaly gets captured on a surveillance camera, the system should detect it and determine if it’s a kidnapping case. Moreover, the system should track the kidnapper, identify his face, and trigger an alarm for our users, in our case, to the nearest police unit.
\subsection{ User Characteristics}
\begin{itemize}
\item Police: Must have basic knowledge in using Android mobile devices to follow up any notification that the system will sent in order to catch the kidnapper.
\end{itemize}
\subsection{System Context}
\begin{figure}[h!]
\centering
\includegraphics[width=15cm,height=8.5cm,keepaspectratio]{./D1.jpeg}
\caption{Architecture of the system.}
\label{fig:D1}
\end{figure}
 \begin{figure}[h!]
\centering
\includegraphics[width=14cm,height=8cm,keepaspectratio]{./D3.jpeg}
\caption{Context Diagram of the system.}
\label{fig:D3}
\end{figure}
\newpage
\section{Functional Requirements}
\subsection{System Functions}\label{System Functions}
\begin{enumerate}
\item The system will be able to predict the event before occurring in order to prevent it and avoid tragic situations.
\item The system will be able to detect the action occurred accurately.
\item The system will be able to track the kidnapper from the location of the incident.
\item The system should apply blurring method for normal citizen's bio metrics in order to enhance privacy in surveillance system.
\item The system should send alert if any failure is detected in the cameras in order to help the maintenance team to solve the problem.
\item The system will send alert message when anomaly behaviour is detected using the fog nodes in the architecture system.
\item The system should provide face recognition feature for the kidnapper and the victim to get their information.
\item The system will filter the incident using video splitting technique in order to be saved and sent to the cloud to save storage.


\end{enumerate}
\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=12.0cm, height=10.0cm]{survillience use case.png}
  \caption{Use Case Diagram}
  \label{usecase}
 \end{minipage}
\end{figure}

\newpage
\subsection{Detailed Functional Specification}

\begin{table}[h!]
\caption{Check failure of the camera}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           &  Check failure of the camera \\ \hline
\textbf{Code}           &  FR01 \\ \hline
\textbf{Priority}       & Extreme \\ \hline
\textbf{Critical}       & It's essential to detect if any failure happens to the video streams and enclose it to efficiently detect an event, avoid network overload, and improve the cloud storage usage \\ \hline
\textbf{Description}    & The system detects if any failure that impacts the usefulness of the video streams (i.e., natural occlusion, disruption) happens. Then, sending an alert of the failure to the maintenance team to recover it   \\ \hline
\textbf{Input}          & Video stream                                                                             \\ \hline
\textbf{Output}         & Boolean if it detects failure or not                                                                             \\ \hline
\textbf{Pre-condition}  & A failure happens in the video streams.                                                                                                                                                                    \\ \hline
\textbf{Post-condition} & A failure is detected and enclosed with an alert to the maintenance team to recover it      \\ \hline
\textbf{Dependency}     & -                                      \\ \hline
\textbf{Risk}           & - \\ \hline
\end{tabular}
\end{table} 

\begin{table}[h!]
\caption{Face blurring}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           &  Face blurring \\ \hline
\textbf{Code}           & FR02 \\ \hline
\textbf{Priority}       & Extreme \\ \hline
\textbf{Critical}       & It's extremely essential to ensure the privacy and identity of the citizens that exposed to privacy violation in the video surveillance \\ \hline
\textbf{Description}    &In the real-time video surveillance after detecting the people's faces, the system uses a blur algorithm to blur the face to be indiscernible.  \\ \hline
\textbf{Input}          & Video stream                                                                                                                                                                   \\ \hline
\textbf{Output}         & Video stream                                                                                                                                                                      \\ \hline
\textbf{Pre-condition}  & Detecting people's faces in real-time video surveillance to blur it               \\ \hline
\textbf{Post-condition} &The detected faces are been blurred      \\ \hline
\textbf{Dependency}     & FR01 – FR03                                       \\ \hline
\textbf{Risk}           & If there is any failure that impacts the usefulness of the video stream \\ \hline
\end{tabular}
\end{table} 

\begin{table}[h!]
\caption{motion detection}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           &  motion detection function \\ \hline
\textbf{Code}           & FR03 \\ \hline
\textbf{Priority}       & Extreme \\ \hline
\textbf{Critical}       & It is really essential; An action needs to be detected in order to take the appropriate action to predict or prevent it.   \\ \hline
\textbf{Description}    & when any action is captured from a surveillance camera, motion detection algorithms, as well as image processing techniques, are applied to detect it.  \\ \hline
\textbf{Input}          & video stream                                                                                                                                                                   \\ \hline
\textbf{Output}         &  video stream                                                                                                                                                                     \\ \hline
\textbf{Pre-condition}  & surveillance camera captures an event.                                                                                                                                                                    \\ \hline
\textbf{Post-condition} & the event gets detected.      \\ \hline
\textbf{Dependency}     & \begin{tabular}[c]{@{}l@{}}
FR01.\\ This function depends on FR01, because if any failure took place on surveillance \\ cameras, the event will not be detected.
\end{tabular}                                       \\ \hline
\textbf{Risk}           & If any failure happens when capturing video streams. \\ \hline
\end{tabular}
\end{table} 



\begin{table}[h!]
\caption{Motion Image Dispatch Function }
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           &   image motion dispatch \\ \hline
\textbf{Code}           &  FR04 \\ \hline
\textbf{Priority}       &  Extreme \\ \hline
\textbf{Critical}       & It is very essential function for the system \\ \hline
\textbf{Description}    & On abnormal motion detection , it gathers location information and dispatches motion image and sends it for the further processing. \\ \hline
\textbf{Input}          & video stream  \\ \hline
\textbf{Output}         & video stream  \\ \hline
\textbf{Pre-condition}  & abnormal motion detected in function FR03        \\ \hline
\textbf{Post-condition} & Dispatch the stream to other processing \\ \hline
\textbf{Dependency}     & FR01-FR03 \\ \hline
\textbf{Risk}           & Camera has any failure in capturing the video streams and can be fixed with FR01\\ \hline
\end{tabular}
\end{table} 

\begin{table}[h!]
\caption{action prediction}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           &  action prediction function \\ \hline
\textbf{Code}           & FR05 \\ \hline
\textbf{Priority}       & High \\ \hline
\textbf{Critical}       & It is important to predict an event before occurring in order to prevent it and avoid tragic situations.  \\ \hline
\textbf{Description}    & after dispatching the needed video stream, an event prediction function can be applied to determine the possible events that could happen.  \\ \hline
\textbf{Input}          & video stream                                                                                                                                                                   \\ \hline
\textbf{Output}         &  Boolean if action is kidnapping.                                                                                                                                                                   \\ \hline
\textbf{Pre-condition}  & Dispatched video stream is processed.                                                                                                                                                            \\ \hline
\textbf{Post-condition} & action is predicted.      \\ \hline
\textbf{Dependency}     & \begin{tabular}[c]{@{}l@{}}
FR01, FR03, FR04.\\  FR01: if any failure took place on surveillance cameras, motion will not be detected \\ in order to predict it. \\
FR03: if motion is not detected, surveillance data cannot be processed further more.\\ So, prediction  will not occur. \\ FR04: video stream needs to be dispatched before forwarding it for further \\ processing.
\end{tabular}                                       \\ \hline
\textbf{Risk}           &  If any failure happens when capturing video streams, if motion was not detected, or if the needed video stream was not dispatched. \\ \hline
\end{tabular}
\end{table} 

\begin{table}[h!]
\caption{Alert Function Description}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           & Alert  \\ \hline
\textbf{Code}           & FR06 \\ \hline
\textbf{Priority}       & Extreme  \\ \hline
\textbf{Critical}       & It is important to alert police by kidnapping incident. \\ \hline
\textbf{Description}    & To maintain the situation, there must an alert send to the police to come urgently and catch the criminal.. \\ \hline
\textbf{Input}          & Video stream , face recognition ,location                                                                                                                                                                 \\ \hline
\textbf{Output}         & Alert                                                                                                                                                                   \\ \hline
\textbf{Pre-condition}  & After detection of kidnapping incident in FR05 and face recognition in FR08, an alert must be sent to police by Fog computing.                      \\ \hline                                                                                     
\textbf{Post-condition} & Alert to police.      \\ \hline
\textbf{Dependency}     & \begin{tabular}[c]{@{}l@{}}
FR05: By detection of the kidnapping incident, \\ FR08: by Face recognition \\ FR07: By detecting the location of the criminal, Fog will send an alert to the police to rescue the victim.
\end{tabular}                                       \\ \hline
\textbf{Risk}           & Failure to send an alert if there is data is missing or there was a difficulty to send an alert. \\ \hline
\end{tabular}
\end{table} 

\begin{table}[h!]
\caption{Kidnapper Tracking Function }
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           & Kidnapper Tracking Function \\ \hline
\textbf{Code}           &  FR07 \\ \hline
\textbf{Priority}       &  low \\ \hline
\textbf{Critical}       & it is a supplementary function in the system\\ \hline
\textbf{Description}    & After detection of a kidnapping incident their should be a tracking for the kidnapper from the location of the incident to help the authorities catch him \\ \hline
\textbf{Input}          & location  \\ \hline
\textbf{Output}         & location  \\ \hline
\textbf{Pre-condition}  & abnormal motion detected FR03,location detetcted and video dispatched in FR04 and predection FR05     \\ \hline
\textbf{Post-condition} & tracing kidnapper location and report the authorities \\ \hline
\textbf{Dependency}     & FR01-FR03-FR04-FR05 \\ \hline
\textbf{Risk}           & Camera has any failure in capturing the video streams and can be fixed with FR01. Or kidnapper runs to a place can't be reached by the system\\ \hline
\end{tabular}
\end{table} 

\begin{table}[h!]
\caption{Face Recognition Function Description}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}
\hline
\textbf{Name}           & Face Recognition  \\ \hline
\textbf{Code}           & FR08 \\ \hline
\textbf{Priority}       & Extreme  \\ \hline
\textbf{Critical}       & It is important to recognize the criminal's face to make it easy for the police to catch him. \\ \hline
\textbf{Description}    & During the crime scene, there should face recognition from a camera sensor to detect the features of the criminal. \\ \hline
\textbf{Input}          & Video stream                                                                                                                                                                 \\ \hline
\textbf{Output}         & Criminal's face                                                                                                                                                                    \\ \hline
\textbf{Pre-condition}  & After detection of the kidnapping incident in FR05, the camera must capture a criminal's face.  \\ \hline                                                                                                                                                           
\textbf{Post-condition} & Face recognition      \\ \hline
\textbf{Dependency}     & \begin{tabular}[c]{@{}l@{}}
FR05: By detection of the kidnapping incident, the camera will capture or recognize \\ the features of the criminal.
Failure in camera when capturing the criminal.
\end{tabular}                                       \\ \hline
\textbf{Risk}           & Failure in camera when capturing criminal. \\ \hline
\end{tabular}
\end{table} 
\FloatBarrier
\newpage
\section{Interface Requirements}
This section describes how the software interfaces with other software products or users for input or output. Examples of such interfaces include library routines, token streams, shared memory, data streams, and so forth. 
\subsection{User Interfaces}
The system is designed to be more simple and facilitate to use and to seem more clear to the user that he must understand the steps that he must do.
Moreover, system provides user by implementing all necessary interactions to make it easy to use.
\subsubsection {GUI}
User Sign up Page: First, user must sign up to have an account to have an access to the website. After making an account,he will login and he can show the alerts that come to him to know the features of the murder, the time of kidnapping and his location.\\
\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=12.0cm, height=10.0cm]{signUp.png}
  \caption{Sign Up}
  \label{Sign Up}
 \end{minipage}
\end{figure}

\\
\newpage
\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=12.0cm, height=8.0cm]{login.png}
  \caption{Login}
  \label{Login}
 \end{minipage}
\end{figure}


\\
\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=10.0cm, height=8.0cm]{alert.png}
  \caption{Alert}
  \label{Alert}
 \end{minipage}
\end{figure}

Alert Page: if there is the kidnapping, an alert will sent to the police by the picture of the murder, location of kidnapping and the time.
\\
\newpage
\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=10.0cm, height=10.0cm]{map.png}
  \caption{Map}
  \label{Map}
 \end{minipage}
\end{figure}

Map Page: After system sends an alert to the police, he will see the details then he will put his location and the location he will go after the murder to catch him.

\subsubsection { CLI}
N/A 


\subsection{Hardware Interfaces}
At this stage, there is no need for hardware as we can use simulators. But on deploying this project in reality,  we need IP surveillance cameras to capture the incidents and personal computers at the end-users sites to help them monitor the system or receive alerts and make records for the crimes.
\subsection{Communications Interfaces}
As our project highly depends on communication among entities, architectures such as fog networking, edge networking, and cloud networking are dominant. To reduce the overload on the network, the processing happens on both the edge and fog nodes to provide real-time response. Moreover, the data then gets transferred to the cloud for further processing.
\subsection {API}
\begin{itemize}
\item Google Maps API, to get the actual location of the event and dispatch it. Also, in tracking the criminal.
\item  Kairos Face Recognition API, for easily real-time detection to detect people's faces.
\item Face Blur API for blurring people's faces, as it's essential to ensure privacy for people's identity in public places.
\end{itemize}

\section{Design Constraints}
 
\subsection{ Standards Compliance}
\subsection{ Hardware Limitations}
 When this project gets applied for real-life use, surveillance cameras can be costly. This project requires various cameras to get installed in multiple areas across a smart city. Moreover, an additional cost gets added for the maintenance of these cameras. 
\subsection{ Other Constraints }
\begin{itemize}
    \item \textbf{Safety and security considerations}: the data transferred through the network and the databases used should be secured against any malicious deformations \cite{Ismagilova2020}.
    \item \textbf{Reliability and Fault tolerance}: Data should not be corrupted or lost in any case, especially while transferring data through the system layers \cite{8666447}.
\end{itemize}

\section{Non-functional Requirements}
\subsection{Security}
The proposed system ensures security and provides data privacy to prevent anonymous and malicious users from using the transmitting data.  Fog and edge computing deal with privacy issues by reducing the amount of data propagation as it processes the data locally which increases the data security. Also, network isolation mechanisms or the physical infrastructure access policies can be applied to provide a more secure and privacy system.
\subsection{Scalability}
The proposed system ensures scalability to handle such massive generated data, it must be constructed to be a real-time scalable up and down system.  It's expected for the fog networks to deal with more nodes.  So, it is needed for them to become acclimated to the system scalability. Otherwise, due to the increment of developing IoT devices, edge services guaranteeing to scale-out accordingly to the enormous amount of devices that being connected to the edge of the network.
\subsection{Performance}
Fog and edge models guaranteeing the best performance real-time system. They have proven that in the bandwidth and the response time especially. For edge computing, nodes need to be placed near the end of the devices. So, it will reduce the amount of receiving data, which leads to low latency and high bandwidth. Also, due to the small amount of transmitted data as it preprocessing locally. Fog computing achieves low latency and high performance efficiently.
\subsection{Interoperability}
It's expected for fog, edge, and cloud to be managed by various providers. So, the system ensures interoperability between them, as it's essential when utilizing services from various cloud providers to have the ability to transfer workloads among them. Also, for fog and edge computing, the components are managed by different providers.

\section{Data Design}
\subsection{Data Description}
Our system collects incident data from streets, uses datasets to train its algorithms, and has a SQL database on the servers where event data and users' data are being saved.
\begin{itemize}
\item The original format of the data is video streams and SQL database records
\item The data captured by the surveillance cameras in the streets, processed using fog nodes, and stored on servers. Users use web forms to communicate with those data.
\item On a large scale The database should be a large dataset as it deals with video streams taken 24/7 and users' information and criminals' information as well.
\item It is expected that we have two users for this system.
\item The data must contain the date and time of each crime; to help the users to report it and arrest the criminal as soon as possible.
\end{itemize}


\subsection{Database design description}
\begin{figure}[h]
\centering
\includegraphics[width=15cm,height=15cm,keepaspectratio]{./Database}
\caption{Database of the software}
\label{fig:D}
\end{figure}
This database in Figure \ref{fig:D} is for the users' software; it also interacts with the criminals' database provided by the social security, and data sets updated frequently to help the performance of detection algorithms used by the system.
\FloatBarrier



\section{Preliminary Object-Oriented Domain Analysis}

\subsection{Inheritance Relationships}

\begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=10.0cm, height=7.5cm]{classdiagram.png}
  \caption{Class Diagram}
  \label{classdiagram}
 \end{minipage}
\end{figure}

\subsection{Class descriptions}
\begin{table}[h!]
\caption{Class Name - officers}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}

 \hline
\textbf{List of Superclasses}  & none                                                      
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & The class represents police officer'data                                                                             
\\ \hline
\textbf{Collaborations}        & associated with shift type,stations,department and aggregated with officers type and notifications.
\\ \hline
\textbf{Attributes}  & officerid:int,officerTypeID:int,firstname:string,last name:string,email:string,
password:string,stationID:int,deployment date:date,shiftID:int,isdeleted:boolean,
notifications[]:notification.
\\ \hline
\textbf{Operations} & 
login(email,password),logout(),signUP(firstname,lastname,email,password,
officersTypeID),updateINFO(officersID,firstname,lastname,email,password),
viewNotifications(notificationID),searchNotifications().

\\ \hline
\textbf{Constraints} & officer is one of the core classes of the application  
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - Officers type}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                    
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents officer's types.                                                                           
\\ \hline
\textbf{Collaborations}        & aggregated with officers.
\\ \hline
\textbf{Attributes}  & ID:int,officerTypeID:int,isdeleted:boolean
\\ \hline
\textbf{Operations} & 
getusertypeID(),insert(),edit(),delete()

\\ \hline
\textbf{Constraints} & cannot work without officers class
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - Admin}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & officers                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & a class represent admin in the system                                                                           
\\ \hline
\textbf{Collaborations}        & extends with officers.
\\ \hline
\textbf{Attributes}  & ID:int,email:string,password:string
\\ \hline
\textbf{Operations} & 
addpoliceofficer(),edit(),delete(),checkFailure(),AddFognodes()

\\ \hline
\textbf{Constraints} & Admin is the main controller in the application.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - shift Type}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents shift types for the police officers.                                                                        
\\ \hline
\textbf{Collaborations}        & associated with officers.
\\ \hline
\textbf{Attributes}  & ID:int,shiftID:int,officerID:int,shiftTimeStarted:datetime,shiftTimeEnded
:datetime,isdeleted:boolean
\\ \hline
\textbf{Operations} & 
getShiftTypeID(),insert(),edit(),delete()
\\ \hline
\textbf{Constraints} & can't work without officers.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - department}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents departments of the police officers.                                                                        
\\ \hline
\textbf{Collaborations}        & associated with officers.
\\ \hline
\textbf{Attributes}  & depCode:int,depDescription:string
\\ \hline
\textbf{Operations} & 
getDepCode(),insert(),edit(),delete()
\\ \hline
\textbf{Constraints} & cannot work without officers.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - stations}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents stations locations of each police officer.                                                                        
\\ \hline
\textbf{Collaborations}        & associated with officers and locations.
\\ \hline
\textbf{Attributes}  & stationID:int,locationID:int
\\ \hline
\textbf{Operations} & 
getLocation()
\\ \hline
\textbf{Constraints} & cannot work without officers and locations.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - notifications}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents the notifications that views to the police officer.                                                                        
\\ \hline
\textbf{Collaborations}        & associated with fog nodes and aggregated with officers.
\\ \hline
\textbf{Attributes}  & ID:int,message:string,FogNodeID:int
\\ \hline
\textbf{Operations} & saveLocation(),sendNotification(),getNearestStation()
getLocation()
\\ \hline
\textbf{Constraints} & cannot work without officers and fognodes.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - fog nodes}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents the fognodes that sends the alerts that came from the edge node to the officers through class notifications                                                                        
\\ \hline
\textbf{Collaborations}        & associated with notifications,locations and cameras.
\\ \hline
\textbf{Attributes}  & FogNodeID:int,data:string
\\ \hline
\textbf{Operations} & prediction(),detection(),trackingLocation()
\\ \hline
\textbf{Constraints} & cannot work without locations and cameras.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - cameras}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents the edge nodes that carries the video data and ready to be sent to fog nodes.                                                                       
\\ \hline
\textbf{Collaborations}        & associated with locations,fognodes and videos.
\\ \hline
\textbf{Attributes}  & cameraID:int,noOfcameras:int,locationID:int
,serialNumber:int
\\ \hline
\textbf{Operations} & getVideos(),sendToFognodes()
\\ \hline
\textbf{Constraints} & cannot work without videos and locations.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - locations}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents the locations of the surveillance camera that the kidnapping event will occur.                                                                
\\ \hline
\textbf{Collaborations}        & associated with cameras,stations,fogNodes
and event.
\\ \hline
\textbf{Attributes}  & LocationID:int,noOfcameras:int,street:string,district:string
\\ \hline
\textbf{Operations} & getLocation(),sendLocation()
\\ \hline
\textbf{Constraints} & cannot work without event class
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - video}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & none                                                                    
\\ \hline
\textbf{Purpose}               & the class represents video data.                                                               
\\ \hline
\textbf{Collaborations}        & associated with cameras,event and aggregated with object.
and event.
\\ \hline
\textbf{Attributes}  & id:int,title:string,duration:double,dateCreated:date,sizeInBytes:int,path:string
\\ \hline
\textbf{Operations} & getSequences(),sendObjects()
\\ \hline
\textbf{Constraints} & cannot work without object class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - object}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & none                                                     
\\ \hline
\textbf{List of Subclasses}    & actors                                                                   
\\ \hline
\textbf{Purpose}               & the class represents objects in the video frame.                                                               
\\ \hline
\textbf{Collaborations}        & associated with region and aggregated with video class. 
\\ \hline
\textbf{Attributes}  & id:int,description:string
\\ \hline
\textbf{Operations} & getVideo(),getFrame(),getRegion()
\\ \hline
\textbf{Constraints} & cannot work without video class.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - actors}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  & object                                                    
\\ \hline
\textbf{List of Subclasses}    & none                                                                
\\ \hline
\textbf{Purpose}               & the class represents actors which is mainly the kidnapper or the victim in the video frame.                                                               
\\ \hline
\textbf{Collaborations}        & associated with position and event. 
\\ \hline
\textbf{Attributes}  & id:int,location:string
\\ \hline
\textbf{Operations} & getEvent(),getPosition()
\\ \hline
\textbf{Constraints} & cannot work without object class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - Region}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                               
\\ \hline
\textbf{List of Subclasses}    & none                                                                  
\\ \hline
\textbf{Purpose}               & the class represents the region of the objects that are in the frame video.                                                             
\\ \hline
\textbf{Collaborations}        & associated with position and object. 
\\ \hline
\textbf{Attributes}  & topLeftX:int,topLeftY:int,width:int,height:int
\\ \hline
\textbf{Operations} & getter(),setter()
\\ \hline
\textbf{Constraints} & cannot work without object and position classes.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - position}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                               
\\ \hline
\textbf{List of Subclasses}    & none                                                                  
\\ \hline
\textbf{Purpose}               & the class represents the exact video frame that the event occur at  be saved and detection will be processed on it.                                      
\\ \hline
\textbf{Collaborations}        & associated with region and actors. 
\\ \hline
\textbf{Attributes}  & startingFrame:double,endingFrame:double
\\ \hline
\textbf{Operations} & getRegion(),getActors()
\\ \hline
\textbf{Constraints} & cannot work without actors class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - event}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                               
\\ \hline
\textbf{List of Subclasses}    & none                                                                  
\\ \hline
\textbf{Purpose}               & the class represents the event of kidnapping.
\\ \hline
\textbf{Collaborations}        & associated with video,actors,locations and aggregated with event status and structure 
\\ \hline
\textbf{Attributes}  & statusCode:id,where:string,when:date,startingFrame:double,endingFrame:double.
\\ \hline
\textbf{Operations} & getshots(),getActors(),getTimeInterval()
\\ \hline
\textbf{Constraints} & cannot work without actors and locations classes.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - event status}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                               
\\ \hline
\textbf{List of Subclasses}    & none                                                                  
\\ \hline
\textbf{Purpose}               & the class represents the status of the event occurred.
\\ \hline
\textbf{Collaborations}        & aggregated with event class. 
\\ \hline
\textbf{Attributes}  & statusCode:id,statusDescription:string
\\ \hline
\textbf{Operations} & getter(),setter()
\\ \hline
\textbf{Constraints} & cannot work without event class.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - structure}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                               
\\ \hline
\textbf{List of Subclasses}    & scene,sequence,shot                                                                  
\\ \hline
\textbf{Purpose}               & the class represents the structure of the event occurred that is divided into shots,scenes and sequence.
\\ \hline
\textbf{Collaborations}        & aggregated with event class. 
\\ \hline
\textbf{Attributes}  & startingFrame:double,endingFrame:double
\\ \hline
\textbf{Operations} & getTimeInterval(Event)
\\ \hline
\textbf{Constraints} & cannot work without event class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - sequence}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    structure                                              
\\ \hline
\textbf{List of Subclasses}    & none                                                                 
\\ \hline
\textbf{Purpose}               & the class represents the sequence of the structure the video surveillance captured when an event occured.
\\ \hline
\textbf{Collaborations}        & aggregated with scene class. 
\\ \hline
\textbf{Attributes}  & id:int,description:string
\\ \hline
\textbf{Operations} & getScenes()
\\ \hline
\textbf{Constraints} & cannot work without structure class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - scene}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    structure                                              
\\ \hline
\textbf{List of Subclasses}    & none                                                                 
\\ \hline
\textbf{Purpose}               & the class represents the scenes of the kidnapping event that occurred.
\\ \hline
\textbf{Collaborations}        & aggregated with shots class. 
\\ \hline
\textbf{Attributes}  & id:int,description:string
\\ \hline
\textbf{Operations} & getSequence(),getShots()
\\ \hline
\textbf{Constraints} & cannot work without structure class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - shots}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    structure                                              
\\ \hline
\textbf{List of Subclasses}    & none                                                                 
\\ \hline
\textbf{Purpose}               & the class represents the shots of the actors in the event that occurred.
\\ \hline
\textbf{Collaborations}        & associated with frame class. 
\\ \hline
\textbf{Attributes}  & id:int,shotTime:time
\\ \hline
\textbf{Operations} & getFrames(),getActorShots()
\\ \hline
\textbf{Constraints} & cannot work without structure class.
\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Class Name - Frame}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                             
\\ \hline
\textbf{List of Subclasses}    & none                                                                 
\\ \hline
\textbf{Purpose}               & the class represents the frame of the actors that occurred in an event. 
\\ \hline
\textbf{Collaborations}        & associated with shot and image classes. 
\\ \hline
\textbf{Attributes}  & FrameNumber:int
\\ \hline
\textbf{Operations} & getImage(),getObject()
\\ \hline
\textbf{Constraints} & cannot work without shot class.
\\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Class Name - Image}
\label{tab:my-table}
\begin{tabular}{|p{0.15\textwidth}|p{0.85\textwidth}|}


 \hline
\textbf{List of Superclasses}  &    none                                             
\\ \hline
\textbf{List of Subclasses}    & none                                                                 
\\ \hline
\textbf{Purpose}               & the class represents the image data of the frame captured.
\\ \hline
\textbf{Collaborations}        & associated with frame class. 
\\ \hline
\textbf{Attributes}  & title:string,format:string,width:int,height:int,texture:string,
histogram:string,rawData:string
\\ \hline
\textbf{Operations} & getFrame()
\\ \hline
\textbf{Constraints} & cannot work without Frame class.
\\ \hline
\end{tabular}
\end{table}
\FloatBarrier
\section{Operational Scenarios}
\subsection{Scenario 1: Intelligent Surveillance System}
As shown in Figure \ref{Activity} and Figure \ref{Sequence}, the system should go through various stages to successfully propose to users the required information to take the appropriate action to stop the kidnapping. First, the system should check for any failures in the surveillance cameras. If camera failure gets detected, the system should determine its cause and manage to fix it. If not, face blurring gets applied to protect people’s privacy while the surveillance data get processed. Moreover, a motion detection algorithm gets used to identify if any abnormal behavior occurred. When motion gets observed, the video stream containing the occasion gets dispatched for further processing. A prediction algorithm gets then implemented to determine if the event is a kidnapping case. If yes, a face recognition algorithm gets used to identify the kidnapper. Moreover, an alarm gets triggered to notify the users, and the kidnapper gets tracked.
 \begin{figure}[!ht]
\centering
 \begin{minipage}{.5\textwidth}
  \includegraphics[width=15cm, height=13cm]{Activity2.jpeg}
  \caption{Activity Diagram}
  \label{Activity}
 \end{minipage}
\end{figure}
\begin{figure}[!ht]

 \begin{minipage}{.5\textwidth}
  \includegraphics[width=18cm, height=15cm]{sequenceDiagram.png}
  \caption{ \centering Sequence Diagram}
  \label{Sequence}
 \end{minipage}
\end{figure}

\newpage
\subsection{Scenario 2: Admin}
The system’s admin controls all the users within the system. He has the ability to:
\begin{itemize}
    \item Add new police officers.
    \item Edit police officers' information.
    \item Delete police officers.
\end{itemize}
\newpage
\subsection{Scenario 3: Police Units}
Police officers can sign up and log into the system. Moreover, when an incident occurs, they get notified via notifications. When they view notifications, they can then go through video streams, identify the kidnappers' faces, and track the location of incidents.




\section{Project Plan}
\includegraphics[width=1\textwidth]{./Taskplan.jpg}

\begin{table}[h]
\centering
\caption{surveillance system for smart cities time plan}
\label{tab:Time Plan}
\begin{tabular}{|l|l|l|l|l|}
\hline
Id & Task               & Start Date & Number of Days & Team Member \\ \hline
1  & Finishing hardware architecture on simulator    & 11/15/2020 &35              & All members        \\ \hline
2  & Collect Dataset    & 1/12/2021 & 23             & sandra,mariam        \\ \hline
3  & Work on GUI        & 1/5/2020 & 15             & nour, samiha,nour        \\ \hline
4  & Anomaly detection enhancement        & 1/5/2020 & 30             & sandra,mariam,nour       \\ \hline
5  & system analysis    & 12/10/2020 & 60              & All members          \\ \hline
6  & Feature Extraction & 2/2/2021 & 12             & All members     \\ \hline
7  & Classification     & 2/10/2021 & 10             & nour,samiha        \\ \hline
8  & Experiments        & 2/3/2021 & 20             & All members    \\ \hline
9  & Writing paper        & 3/15/2021 & 10             & All members    \\ \hline
10  & Writing thesis        & 4/15/2021 & 45             & All members    \\ \hline
\end{tabular}
\end{table}



\section{Appendices}

\subsection{Definitions, Acronyms, Abbreviations}
Fog computing: A mid-layer between edge devices and the cloud, at which data processing occurs. 
\\
\\
Edge computing: An architecture at which data gets processed on devices rather than the cloud to provide low latency.

\subsection{Supportive Documents}
We have done a systematic review, as well as a review paper, which was sent to SSIC 2021(3rd International
Conference on Smart Systems: Innovations in Computing). The paper is accepted now and we are waiting to publish it.The paper is available on github.
   \begin{figure}[h!]
    \centering
    \includegraphics[width=8.0cm, height=9.0cm]{swedyy.jpg}
    \caption{Contacting ELSEWEDY technology company}
    \end{figure}
    \\
    \begin{figure}[h!]
    \centering
    \includegraphics[width=8.0cm, height=9.0cm]{swedy1.jpg}
    \caption{The company's response}
    \end{figure}
   
   \begin{figure}[h!]
    \centering
    \includegraphics[width=8.0cm, height=9.0cm]{paper.jpg}
    \caption{Review Paper}
 \end{figure}


    \begin{figure}[h!]
    \centering
    \includegraphics[width=8.0cm, height=9.0cm]{confrence.png}
    \caption{Acceptance email from SSIC}

\end{figure}
\FloatBarrier
\section {References}

\printbibliography
\end{document}
